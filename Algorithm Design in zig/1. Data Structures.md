# Chapter 1: Data Structures 

In this chapter, the author introduces data structures as crucial elements in optimizing program performance. Just as replacing a faulty organ can save a patient's life, switching a slow or inefficient data structure can significantly improve a program's efficiency. Data structures can affect the speed of operations without changing the program's correctness.

The chapter explains how containers, dictionaries, and priority queues can be implemented using different structures (such as arrays and linked lists) and how each option affects the program's overall performance.

## 1. Contiguous vs. Linked Data Structures

Data structures can be classified as:
  - Contiguously-allocated structures: These include arrays and are based on slabs of memory where data is stored in a sequence.
  - Linked structures: These include linked lists, where data is stored in distinct pieces of memory connected by pointers.

### Arrays

An array is the most common contiguous data structure. Arrays store elements in a fixed-size sequence, and each element can be accessed quickly using its index (like a house number on a street). 
The benefits of arrays include:
  - Constant-time access: Elements can be retrieved instantly by their index.
  - Space efficiency: Arrays do not require extra memory for pointers or metadata.
  - Memory locality: Iterating through arrays is faster due to their continuous placement in memory, allowing processors to take advantage of cache memory.

However, the primary drawback of arrays is their fixed size. If more elements are added beyond the allocated space, the program fails unless you dynamically resize the array. This resizing can be done by doubling the array's size each time it runs out of space. This process requires copying elements into a new, larger array, but on average, each element only moves twice, keeping resizing efficient.

#### Dynamic Arrays in Zig

Here's how to implement a dynamic array in Zig:
```zig
const std = @import("std");

pub fn DynamicArray(comptime T: type) type {
    return struct {
        data: []T,
        capacity: usize,
        len: usize,

        pub fn init(allocator: *std.mem.Allocator, initial_capacity: usize) !*DynamicArray {
            var self = try allocator.create(DynamicArray);
            self.data = try allocator.alloc(T, initial_capacity);
            self.capacity = initial_capacity;
            self.len = 0;
            return self;
        }

        pub fn add(self: *DynamicArray, allocator: *std.mem.Allocator, value: T) !void {
            if (self.len >= self.capacity) {
                const new_capacity = self.capacity * 2;
                self.data = try allocator.realloc(self.data, self.capacity, new_capacity);
                self.capacity = new_capacity;
            }
            self.data[self.len] = value;
            self.len += 1;
        }

        pub fn deinit(self: *DynamicArray, allocator: *std.mem.Allocator) void {
            allocator.free(self.data);
            allocator.destroy(self);
        }
    };
}
```
This Zig code dynamically resizes the array when needed and allows adding new elements efficiently.

### Linked Data Structures
Linked lists are the most common example of linked structures, where each element (or node) contains a data value and a pointer to the next element. The benefits include:
  - Flexibility in size: You can add or remove elements without worrying about predefined sizes or memory overflow (unless memory runs out).
  - Easier insertions and deletions: Moving pointers is faster than shifting all elements, especially with large datasets.

However, linked lists have drawbacks:
  - Additional space for pointers: Each element requires extra memory to store pointers.
  - Lack of random access: You must traverse the list from the beginning to find an element, as there's no indexing.

#### Linked List in Zig

Here’s an example of a singly linked list in Zig:
```zig
const std = @import("std");

pub fn SinglyLinkedList(comptime T: type) type {
    return struct {
        head: ?*Node = null,

        const Node = struct {
            value: T,
            next: ?*Node = null,
        };

        pub fn insert(self: *SinglyLinkedList, value: T, allocator: *std.mem.Allocator) !void {
            var node = try allocator.create(Node);
            node.* = Node{ .value = value, .next = self.head };
            self.head = node;
        }

        pub fn search(self: *SinglyLinkedList, value: T) ?*Node {
            var current = self.head;
            while (current) |node| {
                if (node.value == value) {
                    return node;
                }
                current = node.next;
            }
            return null;
        }

        pub fn delete(self: *SinglyLinkedList, value: T, allocator: *std.mem.Allocator) !void {
            var prev: ?*Node = null;
            var current = self.head;
            while (current) |node| {
                if (node.value == value) {
                    if (prev) |prev_node| {
                        prev_node.next = node.next;
                    } else {
                        self.head = node.next;
                    }
                    allocator.destroy(node);
                    return;
                }
                prev = current;
                current = node.next;
            }
        }
    };
}
```
This code defines a basic linked list that supports insertion, searching, and deletion of elements.

## Takeaway Points:

  - Arrays offer fast access and memory efficiency but are fixed in size unless dynamically resized.
  - Linked lists are more flexible but require more memory for pointers and don’t support fast random access.
  - Dynamic memory allocation in both arrays and linked lists allows flexibility but requires thoughtful management to avoid inefficiencies.

Each data structure comes with tradeoffs, and understanding them allows for designing more efficient algorithms based on the specific needs of your program.

## 3.2: Stacks and Queues

A container is a data structure that stores and retrieves data items, but it does so independently of the content of the data. Unlike dictionaries, which retrieve items based on key values or content, containers focus on the order in which items are added and removed.
### Two Main Types of Containers:
  - Stacks (LIFO - Last In, First Out):
     - Definition: A stack retrieves data in the reverse order of insertion. The last item inserted is the first to be removed.
     - Common Operations:
         - Push: Insert an item at the top of the stack.
         - Pop: Remove and return the top item from the stack.
      - Real-World Example: When people enter a crowded subway car, they tend to exit in the reverse order (last person in, first person out).
      - Algorithmic Example: Often used in recursive algorithms, where function calls are placed on the call stack in LIFO order.
  - Queues (FIFO - First In, First Out):
      - Definition: A queue retrieves data in the same order in which it was inserted. The first item inserted is the first to be removed.
      - Common Operations:
          - Enqueue: Insert an item at the back of the queue.
          - Dequeue: Remove and return the front item from the queue.
      - Real-World Example: A typical queue at a grocery store, where the first person in line is the first to be served.
      - Algorithmic Example: Breadth-First Search (BFS) in graph traversal uses queues to explore nodes level by level.

### Implementation Details:
Stacks and queues can be implemented using arrays or linked lists:
  - Array-based: Best when the size of the container is known ahead of time.
  - Linked list-based: Flexible when the size is unknown, as it grows dynamically.

### Zig Code for Stacks and Queues
Stack Implementation (using array)

```zig
const std = @import("std");

const Stack = struct {
    items: []i32,
    count: usize,

    pub fn init(max_size: usize) Stack {
        return Stack{
            .items = std.heap.page_allocator.alloc(i32, max_size) catch unreachable,
            .count = 0,
        };
    }

    pub fn push(self: *Stack, value: i32) void {
        self.items[self.count] = value;
        self.count += 1;
    }

    pub fn pop(self: *Stack) ?i32 {
        if (self.count == 0) {
            return null; // Stack is empty
        }
        self.count -= 1;
        return self.items[self.count];
    }

    pub fn is_empty(self: *Stack) bool {
        return self.count == 0;
    }
};

pub fn main() void {
    var stack = Stack.init(10); // A stack of size 10
    stack.push(42);
    stack.push(15);
    
    const top = stack.pop();
    if (top) |value| {
        std.debug.print("Popped: {}\n", .{value});
    } else {
        std.debug.print("Stack is empty!\n", .{});
    }
}
```
Explanation:

  - The Stack struct maintains an array of integers and a counter for the current number of elements.
  - push inserts an element at the top of the stack.
  - pop removes and returns the top element.
  - The stack is initialized with a maximum size, ensuring we have space allocated for elements.

### Queue Implementation (using linked list)
```zig
const std = @import("std");

const Queue = struct {
    head: ?*Node = null,
    tail: ?*Node = null,

    const Node = struct {
        value: i32,
        next: ?*Node,
    };

    pub fn enqueue(self: *Queue, value: i32) void {
        const new_node = std.heap.page_allocator.create(Node) catch unreachable;
        new_node.* = Node{ .value = value, .next = null };
        
        if (self.tail) |tail_node| {
            tail_node.next = new_node;
        } else {
            self.head = new_node;
        }
        self.tail = new_node;
    }

    pub fn dequeue(self: *Queue) ?i32 {
        if (self.head) |head_node| {
            const result = head_node.value;
            self.head = head_node.next;
            if (self.head == null) {
                self.tail = null;
            }
            return result;
        }
        return null; // Queue is empty
    }
};

pub fn main() void {
    var queue = Queue{};
    queue.enqueue(10);
    queue.enqueue(20);
    
    const front = queue.dequeue();
    if (front) |value| {
        std.debug.print("Dequeued: {}\n", .{value});
    } else {
        std.debug.print("Queue is empty!\n", .{});
    }
}
```
##### Explanation:

  - The Queue struct uses a linked list of Node elements, each holding a value and a reference to the next node.
  - enqueue adds a new element to the back of the queue.
  - dequeue removes and returns the element from the front of the queue.
  - If the queue is empty, dequeue returns null.

#### Summary
  - Stacks: Simple and efficient data structure for LIFO operations, useful in recursive algorithms or tasks where the order of processing doesn't matter.
  - Queues: Fair structure for FIFO operations, useful in situations where fairness is required (e.g., simulations, job scheduling).
  - Both can be implemented with arrays or linked lists, with trade-offs in terms of efficiency depending on whether a fixed size is known upfront.


## 3.3: Dictionaries

This section explains how a dictionary data structure allows data access by content, not by position. A dictionary's main operations include searching for an element by key, inserting elements, and deleting elements. Some dictionaries also support additional operations, such as finding the minimum or maximum value and retrieving the predecessor or successor of a given key. These operations make dictionaries suitable for tasks like removing duplicates from a mailing list or iterating through sorted elements.

Various data structures can implement dictionaries, including arrays and linked lists. These implementations offer different performance trade-offs for operations like searching, inserting, deleting, and traversing. The section explores how different data structures (unsorted/sorted arrays, singly/doubly linked lists) handle dictionary operations with varying performance.

The main takeaway is that data structure design requires balancing the efficiency of different operations. No single structure performs all operations the best, so you choose based on which operations are most important.
Key Operations of a Dictionary:

  - Search(D, k): Find the element with key k.
  - Insert(D, x): Add element x to the dictionary.
  - Delete(D, x): Remove element x from the dictionary.
  - Max(D) or Min(D): Find the maximum or minimum key.
  - Predecessor(D, k) or Successor(D, k): Find the item before or after k in sorted order.

Now let’s look at the two different implementations for dictionaries (unsorted and sorted arrays), compare their time complexity, and translate the operations into Zig.
### 1. Unsorted Array Operations (in Zig)

`Search (O(n))`
##### Searching in an unsorted array requires checking each element until the key is found.
```zig
fn search(array: []const i32, key: i32) ?i32 {
    for (array) |elem, idx| {
        if (elem == key) return idx;
    }
    return null;
}
```
`Insert (O(1))`

##### Inserting into an unsorted array is simply adding the element to the next available position.
```zig
fn insert(array: *[]i32, value: i32, len: *usize) void {
    array[*len] = value;
    *len += 1;
}
```
`Delete (O(1) if pointer is known)`

##### Deleting an element can be optimized by replacing the deleted element with the last element, then reducing the array size.
```zig
fn delete(array: *[]i32, index: usize, len: *usize) void {
    array[index] = array[*len - 1];
    *len -= 1;
}
```
`Minimum and Maximum (O(n))`

##### Finding the minimum or maximum value in an unsorted array requires scanning all elements.
```zig
fn min(array: []const i32) i32 {
    var min_value = array[0];
    for (array) |elem| {
        if (elem < min_value) min_value = elem;
    }
    return min_value;
}

fn max(array: []const i32) i32 {
    var max_value = array[0];
    for (array) |elem| {
        if (elem > max_value) max_value = elem;
    }
    return max_value;
}
```

`Predecessor and Successor (O(n))`

##### Finding the predecessor or successor requires scanning the array to find the nearest values before or after the key.
```zig
fn predecessor(array: []const i32, key: i32) ?i32 {
    var pred: ?i32 = null;
    for (array) |elem| {
        if (elem < key and (pred == null or elem > pred)) pred = elem;
    }
    return pred;
}

fn successor(array: []const i32, key: i32) ?i32 {
    var succ: ?i32 = null;
    for (array) |elem| {
        if (elem > key and (succ == null or elem < succ)) succ = elem;
    }
    return succ;
}
```
### 2. Sorted Array Operations (in Zig)

Sorted arrays allow faster searching but make insertion and deletion more expensive because elements need to be shifted.

`Search (O(log n))`

##### Binary search is efficient for finding elements in a sorted array.
```zig
fn binarySearch(array: []const i32, key: i32) ?i32 {
    var lo: usize = 0;
    var hi: usize = array.len - 1;
    
    while (lo <= hi) {
        const mid = (lo + hi) / 2;
        if (array[mid] == key) return mid;
        if (array[mid] < key) lo = mid + 1;
        else hi = mid - 1;
    }
    return null;
}
```

`Insert (O(n))`

##### Inserting an element into a sorted array requires shifting all larger elements to the right to maintain the sorted order.
```zig
fn insertSorted(array: *[]i32, value: i32, len: *usize) void {
    var i = *len;
    while (i > 0 and array[i - 1] > value) : (i -= 1) {
        array[i] = array[i - 1];
    }
    array[i] = value;
    *len += 1;
}
```

`Delete (O(n))`

##### Deleting from a sorted array requires shifting elements to close the gap.
```zig
fn deleteSorted(array: *[]i32, index: usize, len: *usize) void {
    for (index..*len - 1) |i| {
        array[i] = array[i + 1];
    }
    *len -= 1;
}
```
- Unsorted arrays are quick for inserting (just drop the element at the end) but slow for searching, deleting, and traversing since everything is jumbled.
- Sorted arrays make searching faster with binary search but inserting and deleting slower because you need to move elements around to keep the order.
- In both cases, the design of the data structure determines the trade-offs between speed and efficiency for different operations.

## 3.4: Binary Search Trees
Binary search trees (BST) provide a data structure that balances fast search operations with flexible updates. In a BST, each node is labeled with a key such that the keys in the left subtree are smaller than the node’s key, and those in the right subtree are greater. This ensures efficient searching, as it can be done in O(h) time, where h is the height of the tree. However, the tree's shape depends on the order of inserted nodes, potentially leading to unbalanced trees with poor performance (linear height).

Key operations on BSTs include:

  - Searching: Done recursively by traversing left or right subtrees depending on the value of the key.
  - Finding Minimum/Maximum: The smallest node is the leftmost descendant, and the largest is the rightmost.
  - Traversal: Nodes can be visited in sorted order (in-order traversal) by recursively visiting the left subtree, processing the root, and then visiting the right subtree.
  - Insertion: Inserting a new node involves searching for the correct spot and placing the new node in place of a NULL pointer.
  - Deletion: Deletion is more complex, especially when a node has two children. The node is replaced by its successor, and the tree is restructured accordingly.

### Zig Code Translation and Explanation

Here's the Zig version of the binary search tree operations, focusing on simplicity and readability:
```zig
const std = @import("std");

const ItemType = i32;

const Tree = struct {
    item: ItemType,
    parent: ?*Tree = null,
    left: ?*Tree = null,
    right: ?*Tree = null,
};

// Searching in a tree
fn searchTree(l: ?*Tree, x: ItemType) ?*Tree {
    if (l == null) return null;
    if (l.item == x) return l;
    if (x < l.item) {
        return searchTree(l.?.left, x);
    } else {
        return searchTree(l.?.right, x);
    }
}

// Finding the minimum element
fn findMinimum(t: ?*Tree) ?*Tree {
    var min = t;
    while (min != null and min.?.left != null) {
        min = min.?.left;
    }
    return min;
}

// In-order tree traversal (visits nodes in sorted order)
fn traverseTree(l: ?*Tree) void {
    if (l != null) {
        traverseTree(l.?.left);
        std.debug.print("{}\n", .{ l.?.item });
        traverseTree(l.?.right);
    }
}

// Inserting a new node
fn insertTree(l: *?*Tree, x: ItemType, parent: ?*Tree) void {
    var current = l.*;
    if (current == null) {
        const new_node = std.heap.c_allocator.alloc(Tree, 1).?;
        new_node.item = x;
        new_node.left = null;
        new_node.right = null;
        new_node.parent = parent;
        l.* = new_node;
        return;
    }
    if (x < current.item) {
        insertTree(&current.left, x, current);
    } else {
        insertTree(&current.right, x, current);
    }
}
```
### Explanation

  1. Tree Structure:
        The Tree structure represents a binary search tree node. Each node holds an item, and pointers to its parent, left, and right children.

  2. Searching:
        The searchTree function recursively searches for the key x. It traverses left if x is smaller than the current node’s item and right if it's larger.

  3. Finding the Minimum:
        The findMinimum function follows the leftmost path from the root to find the smallest item in the tree.

  4. Traversal:
        The traverseTree function implements in-order traversal, which visits nodes in ascending order by first visiting the left child, then processing the node, and finally visiting the right child.

  5. Insertion:
        The insertTree function inserts a new node by recursively traversing the tree until it finds an empty spot (a NULL pointer). The new node is then linked into the tree.


Binary search trees allow you to efficiently organize data such that you can quickly find, insert, and delete elements. You start at the root and move left or right based on the values you are comparing. By following this rule, the tree keeps everything in order, so searching for any element becomes fast.

For example, to find the smallest item in the tree, you can always go left until you can't go further. Similarly, to traverse the tree in sorted order, you visit the left side first, then process the node, and then visit the right side. This makes it easy to sort items using a binary search tree.

Inserting a new item means finding the correct spot in the tree where it should go and then attaching it as a new leaf. Deleting a node is trickier because you need to reconnect the remaining parts of the tree, especially if the node has two children.


## 3.5: Priority Queues
Priority Queues Overview: Priority queues are essential data structures that allow efficient management of items by their importance (or priority). Instead of sorting all items each time a new one arrives, a priority queue allows insertion, finding the minimum (or maximum) element, and deleting it efficiently.

The basic operations in a priority queue include:

  - Insert(Q, x): Inserts an item x with a priority k into the queue Q.
  - Find-Minimum(Q): Returns the item with the smallest priority in Q.
  - Delete-Minimum(Q): Removes the item with the smallest priority in Q.

Different data structures (like arrays and binary search trees) can be used to implement priority queues, but each has trade-offs in terms of time complexity for these operations.

Time Complexity for Different Data Structures:

| Data Structure  | Insert  | Find-Minimum  | Delete-Minimum  |
|-----------------|---------|---------------|-----------------|
| Unsorted Array	| O(1)	  |     O(n)	    |      O(n)       | 
| Sorted Array  	| O(n)	  |     O(1)	    |      O(1)       | 
| Balanced Tree	  | O(log n)|     O(1)	    |      O(log n)   | 

The key to optimizing priority queues is keeping track of the minimum element efficiently. By updating pointers to the minimum element on each insertion and carefully managing deletions, the time complexity for these operations can be reduced.

### Explanation

Imagine you're managing tasks based on their importance. Instead of constantly re-sorting the tasks every time a new one arrives, you can use a priority queue. This queue makes it easy to add new tasks, find the most important one quickly, and remove tasks that are completed—all without reordering the entire list.

For example, if you're using an unsorted list, adding a new task is instant (O(1)), but finding the most important task takes longer (O(n)). On the other hand, a sorted list makes it easy to find the top task quickly, but adding a new task becomes slower because you have to insert it in the correct position.

Using efficient data structures like balanced trees improves this process, making both insertion and retrieval faster and more manageable.

#### Zig Code Example for Priority Queue Operations

Let's implement a simple priority queue in Zig using an array and a struct to handle tasks with priorities. We will include basic operations like insert, find-minimum, and delete-minimum.
```zig
const std = @import("std");

const Task = struct {
    key: usize,  // The priority key (smaller key = higher priority)
    value: []const u8, // The task description
};

const PriorityQueue = struct {
    tasks: []Task, // Dynamic array to store tasks
    minIndex: usize, // Index of the minimum element in the queue

    pub fn init(allocator: *std.mem.Allocator) PriorityQueue {
        return PriorityQueue{
            .tasks = allocator.alloc(Task, 0) catch unreachable,
            .minIndex = 0,
        };
    }

    pub fn insert(self: *PriorityQueue, allocator: *std.mem.Allocator, key: usize, value: []const u8) void {
        // Insert a new task with priority key
        const task = Task{ .key = key, .value = value };
        self.tasks = allocator.realloc(self.tasks, self.tasks.len + 1) catch unreachable;
        self.tasks[self.tasks.len - 1] = task;

        // Update minIndex if needed
        if task.key < self.tasks[self.minIndex].key {
            self.minIndex = self.tasks.len - 1;
        }
    }

    pub fn findMinimum(self: *PriorityQueue) ?Task {
        if (self.tasks.len == 0) return null;
        return self.tasks[self.minIndex];
    }

    pub fn deleteMinimum(self: *PriorityQueue, allocator: *std.mem.Allocator) void {
        if (self.tasks.len == 0) return;

        // Remove the minimum task
        const lastIndex = self.tasks.len - 1;
        self.tasks[self.minIndex] = self.tasks[lastIndex];
        self.tasks = allocator.realloc(self.tasks, lastIndex) catch unreachable;

        // Recalculate minIndex
        if (self.tasks.len > 0) {
            self.minIndex = 0;
            for (var i = 1; i < self.tasks.len; i += 1) {
                if (self.tasks[i].key < self.tasks[self.minIndex].key) {
                    self.minIndex = i;
                }
            }
        }
    }
};

pub fn main() !void {
    const allocator = std.heap.page_allocator;

    var pq = PriorityQueue.init(allocator);
    pq.insert(allocator, 10, "Task 1");
    pq.insert(allocator, 5, "Task 2");
    pq.insert(allocator, 15, "Task 3");

    const minTask = pq.findMinimum() orelse return;
    std.debug.print("Minimum Task: {}\n", .{minTask.value});

    pq.deleteMinimum(allocator);

    const nextMinTask = pq.findMinimum() orelse return;
    std.debug.print("Next Minimum Task: {}\n", .{nextMinTask.value});
}
```
#### Key Points:

  - Insert: Adds a new task to the queue and updates the index of the minimum task if necessary.
  - Find-Minimum: Returns the task with the highest priority (lowest key).
  - Delete-Minimum: Removes the task with the highest priority and recalculates the minimum.

This basic implementation demonstrates how priority queues work, providing a solid foundation for more advanced algorithms and optimizations later on.

## 3.7 Hashing and Strings

Hash tables are efficient tools for maintaining dictionaries, which store key-value pairs and enable fast lookups. The core idea of a hash table is to use a mathematical function (hash function) to convert keys into integers, which serve as indices in an array. This allows constant-time lookups, given the index.
Hash Function Explanation:

  - Mapping Keys to Integers: Each key, such as a string, is converted into a large integer. For example, if the string is "ABC", the process converts each character to an integer based on its position in the alphabet and combines them.
  
  - Example of Hash Function: For a string S of length |S|, the function:

    $H(S) = ∑ [α^(|S| - (i + 1)) * char(S[i])]$

    maps the string into a unique but large integer. Here, α is the size of the alphabet (e.g., 26 for English), and char(S[i]) represents the numeric value of the character.

  - Modulus Operation: The resulting large integer is reduced to fit into the size of the hash table (m) by taking the modulus H(S) % m. This gives an index between 0 and m-1.

### Collision Resolution:

Collisions occur when two different keys map to the same index in the hash table. There are two common methods to handle this:

  - Chaining: Each index in the hash table points to a linked list. If multiple keys hash to the same index, they are stored in the list. Operations like search, insert, and delete work by traversing these lists, and if the table is large enough, the lists remain short.
  
  - Open Addressing: If a key hashes to an already occupied index, this method searches for the next available spot by probing the table. For instance, in sequential probing, you check the next slot until you find an empty one.

### Key Operations:

  - Search: Use the hash function to compute the index. If there’s a collision (multiple keys at the same index), look through the linked list (chaining) or probe until you find the key (open addressing).
  
  - Insert: Find the index using the hash function. If the spot is free, insert it; otherwise, handle the collision.
  
  - Delete: In chaining, remove the item from the linked list. In open addressing, deletion may require rehashing following elements, as removing one might break the chain of insertions.

### Time Complexities:

For n items and a hash table of size m:

  - Search: Expected time is O(n/m) in chaining, worst-case O(n).
  - Insert: Expected O(1), worst-case O(1).
  - Delete: Expected O(1), worst-case O(1).

### Hashing for Efficient String Matching:

Hashing can speed up string operations like substring matching. For instance, the Rabin-Karp algorithm uses hashing to find patterns in text. Instead of checking all characters in a pattern against a text, you can hash the pattern and each substring of the text. If the hashes match, a further check confirms the pattern.

This results in more efficient string matching, with the complexity depending on the quality of the hash function.

#### Zig Implementation of Hashing

The following is a Zig implementation of a basic hash function, using chaining for collision resolution:
```zig
const std = @import("std");

const Entry = struct {
    key: []const u8,
    value: i32,
    next: ?*Entry,
};

const HashTable = struct {
    table: []?*Entry,
    size: usize,

    pub fn init(allocator: *std.mem.Allocator, size: usize) !HashTable {
        return HashTable{
            .table = try allocator.alloc(?*Entry, size),
            .size = size,
        };
    }

    fn hash(self: *HashTable, key: []const u8) usize {
        var hash_value: usize = 0;
        const alpha: usize = 256;
        for (key) |c| {
            hash_value = hash_value * alpha + @as(usize, c);
        }
        return hash_value % self.size;
    }

    pub fn insert(self: *HashTable, allocator: *std.mem.Allocator, key: []const u8, value: i32) !void {
        const index = self.hash(key);
        var new_entry = try allocator.create(Entry);
        new_entry.* = Entry{
            .key = key,
            .value = value,
            .next = self.table[index],
        };
        self.table[index] = new_entry;
    }

    pub fn search(self: *HashTable, key: []const u8) ?i32 {
        const index = self.hash(key);
        var current = self.table[index];
        while (current) |entry| {
            if (std.mem.eql(u8, entry.key, key)) {
                return entry.value;
            }
            current = entry.next;
        }
        return null;
    }

    pub fn deinit(self: *HashTable, allocator: *std.mem.Allocator) void {
        for (self.table) |entry| {
            var current = entry;
            while (current) |e| {
                const next = e.next;
                allocator.destroy(e);
                current = next;
            }
        }
        allocator.free(self.table);
    }
};
```
Explanation:

  - Hash Function: This function converts a string key into an integer by treating each character as a digit in base 256 (for simplicity). The modulus with the table size ensures the result fits within the array.
  - Collision Handling (Chaining): If two keys hash to the same value, the second key is stored in a linked list at the same index. This preserves the correctness of the table.
  - Insert/Search: Insertions add new entries at the head of the list at each index. Searching traverses the list until the key is found.

## 3.8: Specialized Data Structures

This section introduces specialized data structures, which are crucial for handling more structured objects like points in space, strings, and graphs. These are beyond basic unstructured collections of items.

The main categories of specialized data structures are:

  - String Data Structures: Strings are usually represented as arrays of characters. More advanced structures like suffix trees and suffix arrays help in making string operations like pattern matching faster. These are covered in detail in later chapters.
  
  - Geometric Data Structures: These are used to represent data in geometric space, often for points and regions. For example, polygons can be represented by arrays of points, with their boundaries defined by line segments. Spatial data structures like kd-trees organize such points for fast searches.
  
  - Graph Data Structures: Graphs can be represented in two main ways: adjacency matrices or adjacency lists. The choice of representation affects the efficiency of graph algorithms, and specific techniques are discussed in later sections.
  
  - Set Data Structures: Sets are often represented with dictionaries (for fast lookups) or bit vectors (boolean arrays). Special data structures like union-find help in managing set partitions, discussed further in later chapters.

These specialized data structures are designed with specific operations in mind, and understanding their structure and application is key to writing efficient algorithms.
Explanation in Simple Terms

  - String Data Structures: These are used to handle sequences of characters (words, texts). Suffix trees and arrays are like pre-made maps that make it faster to search for certain parts of words or patterns.
  
  - Geometric Data Structures: Imagine you have points or shapes (like polygons) on a piece of paper. These data structures help keep track of them so you can find or manipulate them quickly. For example, kd-trees help you quickly find a point's location.
  
  - Graph Data Structures: Graphs are networks of connected things (nodes). You can store these networks either as lists of who is connected to whom (adjacency lists) or as a big grid showing all the connections (adjacency matrices). The way you store this can make some operations faster.
  
  - Set Data Structures: Sets are collections of items, like a group of numbers. You can store sets either with dictionaries (which make it easy to check if an item is in the set) or with bit arrays (where each bit tells if an item is present or not). There are also advanced structures for when you need to divide sets into groups.

### Code Example in Zig

Here's a translation of a basic bit vector example from C to Zig. In this example, we'll represent a set of integers where the presence of an integer is tracked using a bit vector.
##### Zig Code for Bit Vector:
```zig
const std = @import("std");

const BitVector = struct {
    bits: []u8,

    pub fn init(allocator: *std.mem.Allocator, size: usize) !*BitVector {
        var self = try allocator.create(BitVector);
        self.bits = try allocator.alloc(u8, (size + 7) / 8);  // 1 byte = 8 bits
        std.mem.set(self.bits, 0);  // Set all bits to 0
        return self;
    }

    pub fn set(self: *BitVector, index: usize) void {
        const byte_index = index / 8;
        const bit_position = index % 8;
        self.bits[byte_index] |= (1 << bit_position);  // Set the bit to 1
    }

    pub fn clear(self: *BitVector, index: usize) void {
        const byte_index = index / 8;
        const bit_position = index % 8;
        self.bits[byte_index] &= ~(1 << bit_position);  // Set the bit to 0
    }

    pub fn is_set(self: *BitVector, index: usize) bool {
        const byte_index = index / 8;
        const bit_position = index % 8;
        return (self.bits[byte_index] & (1 << bit_position)) != 0;
    }

    pub fn free(self: *BitVector, allocator: *std.mem.Allocator) void {
        allocator.free(self.bits);
        allocator.destroy(self);
    }
};

pub fn main() !void {
    const allocator = std.heap.page_allocator;
    var set = try BitVector.init(allocator, 100);  // Create a bit vector for a set of 100 items

    set.set(5);  // Add element 5 to the set
    if (set.is_set(5)) {
        std.debug.print("5 is in the set.\n", .{});
    }

    set.clear(5);  // Remove element 5 from the set
    if (!set.is_set(5)) {
        std.debug.print("5 is no longer in the set.\n", .{});
    }

    set.free(allocator);
}
```

#### How it Works:

  - The BitVector is a simple data structure that uses an array of bytes (8 bits each) to represent a set. Each bit represents whether an element is in the set or not.
  - set(index) marks an element as present by setting the corresponding bit to 1.
  - clear(index) removes an element by setting its bit back to 0.
  - is_set(index) checks if a given bit is set, meaning that the element is present in the set.

This approach is memory-efficient and fast for checking set membership or toggling elements, especially for large ranges of integers.
