# Advanced Process Management.md
Chapter 6 covers some complex but fascinating aspects of process scheduling and management. Here’s a breakdown to guide you through each section. I’ll provide a high-level explanation of each concept and follow up with Zig examples to demonstrate the basics.

## 1. Process Scheduling

The process scheduler is a critical part of the OS kernel. It decides which process runs when, handling all runnable processes (those not blocked or sleeping) and ensuring they execute in a fair order. This fairness allows for the appearance of multiple tasks running concurrently, known as multitasking. Modern OSs, including Linux, typically use preemptive multitasking, where the scheduler determines when to pause one process and start another, rather than waiting for a process to voluntarily yield control.

  - Runnable Process: Not blocked, ready to execute when selected.
  - Blocked Process: Waiting on I/O or other resources and not runnable.

Let's look at an example to see how Zig handles a basic scheduler interaction.

Zig Example
Here's a simple structure that demonstrates a preemptive-like scheduler by simulating processes. We won’t implement a real scheduler in Zig, as this involves low-level OS/kernel calls, but we’ll mimic scheduling behavior using a loop and control flow to manage tasks.

```zig
const std = @import("std");

fn mockProcess(name: []const u8) void {
    // Simulate a task that "runs"
    std.debug.print("Running process: {}\n", .{name});
}

pub fn main() void {
    const processQueue = [_][]const u8{"Process A", "Process B", "Process C"};
    var index: usize = 0;

    // Mock scheduler loop to "run" each process
    while (true) {
        mockProcess(processQueue[index]);

        // Simulate "preemption" by moving to the next process
        index = (index + 1) % processQueue.len;
        std.time.sleep(1_000_000_000); // Sleep for 1 second to simulate a timeslice
    }
}
```

In this example, mockProcess simulates processes, and the loop represents a basic scheduler moving between processes.

## 2. Timeslices

A timeslice is the maximum time a process can run before being preempted (interrupted) by the scheduler. Longer timeslices improve throughput but can lead to poor interactive performance, while shorter timeslices improve responsiveness at the cost of efficiency. However, Linux's Completely Fair Scheduler (CFS) abolishes the traditional concept of fixed timeslices and instead aims for fair CPU time distribution.

## 3. I/O-Bound vs. Processor-Bound Processes

  - I/O-Bound Processes: Spend most of their time waiting for I/O, often blocked (e.g., file operations or user input). They don't need large timeslices but benefit from quick reactivation once I/O completes.
  - Processor-Bound Processes: Consume all available CPU time without blocking (e.g., intensive computations). They need longer timeslices to maximize CPU usage efficiency.

Zig Example: Simulating Different Process Types

This example shows how an I/O-bound process would differ from a CPU-bound one:

```zig

fn cpuBoundProcess() void {
    // This would be a CPU-intensive task
    var sum: u64 = 0;
    for (std.math.range(1, 1_000_000)) |i| {
        sum += i;
    }
    std.debug.print("CPU-bound process completed\n", .{});
}

fn ioBoundProcess() void {
    // Simulate waiting for I/O
    std.time.sleep(2_000_000_000); // Sleep for 2 seconds
    std.debug.print("I/O-bound process completed\n", .{});
}

pub fn main() void {
    std.debug.print("Starting CPU-bound process...\n", .{});
    cpuBoundProcess();
    std.debug.print("Starting I/O-bound process...\n", .{});
    ioBoundProcess();
}
```

Here, the cpuBoundProcess performs continuous calculations, while the ioBoundProcess simulates an I/O wait.
## 4. Preemptive Scheduling

In preemptive scheduling, the OS forcibly pauses a running process after its timeslice ends and switches to another. This ensures all runnable processes eventually get CPU time, which is particularly important in a multitasking system.

Linux’s CFS uses a fair queuing algorithm that balances CPU time based on a "virtual runtime," tracking how much time each process has received relative to others and adjusting their priorities accordingly.

### Concept Summary

In Zig, direct interaction with the scheduler is limited since process scheduling is managed at the OS level, but the concepts can be demonstrated through careful control of execution flow and timing in examples like the ones above.

## The Completely Fair Scheduler

### 1. The Completely Fair Scheduler (CFS)
Concept Overview:

The CFS represents a shift from traditional Unix process schedulers, which typically rely on priority and timeslice to allocate CPU time. In previous schedulers:

  - Timeslice: Each process is assigned a fixed slice of CPU time, running until this time is exhausted.
  - Priority: Processes with higher priority run before those with lower priority.

While straightforward, these timeslice-based approaches weren’t optimized for modern desktops and mobile devices, which require smooth interactivity and fairness.
How CFS Works:

Instead of timeslices, CFS uses a proportional time allocation model:

  - Fair Scheduling: Each process receives a proportion of CPU time, determined by the number of runnable processes. For example, if there are NN processes, each starts with 1/N1/N of the CPU.
  - Nice Value Adjustment: The proportion of time a process gets is adjusted by its nice value, where:
      - A nice value of 0 represents a weight of 1.
      - Lower nice values (higher priority) increase a process’s weight, giving it more CPU time.
      - Higher nice values (lower priority) reduce a process’s weight.

This adjustment helps CFS allocate time based on priority but without fixed timeslices, leading to smoother, more balanced performance.

### Target Latency and Minimum Granularity:
  - Target Latency: This is the period within which each runnable process should ideally get its proportional CPU time. For example, if the target latency is 20 ms and there are two runnable processes with equal weight, each would run for 10 ms within that cycle.
  - Minimum Granularity: To prevent excessive context switching (which would waste CPU time), CFS enforces a minimum duration that each process can run, ensuring system efficiency even with many processes.

In practice, CFS dynamically adjusts process run time, maintaining fairness and interactive responsiveness by enforcing these time constraints.

### 2. Yielding the Processor
Concept Overview:
Although Linux uses preemptive multitasking (where the OS scheduler decides when to switch tasks), it also allows processes to voluntarily yield the processor. This is done using the sched_yield() system call, which suspends the calling process temporarily, allowing other processes to run.
Use Cases:
  - Inter-process Coordination: In scenarios where one process waits for another, sched_yield() could theoretically be used to wait until the other process is ready. However, Unix developers typically prefer event-driven, blocking mechanisms (e.g., pipes), which are more efficient than yielding in busy loops.
  - Avoiding CPU Overuse: Processor-intensive applications may call sched_yield() periodically to reduce system impact. However, this is often unnecessary since the kernel scheduler can handle global CPU distribution more effectively than individual processes can.

### Why It's Rarely Used:

In a preemptive multitasking environment, the kernel can manage scheduling more optimally than user-space applications. For instance:

  - Event-driven Design: Processes should ideally wait on blockable resources (like file descriptors), allowing the kernel to handle wake-ups rather than manually yielding.
  - Efficient Thread Locking: Modern systems use efficient mechanisms like futexes for user-space locks, eliminating many uses for sched_yield().

### Example of sched_yield() Usage:

In rare cases, such as when building a very low-level or CPU-intensive process, you might use sched_yield():

```zig
const std = @import("std");
const Sched = @import("sched");

pub fn main() !void {
    while (condition_not_met()) {
        if (Sched.yield() != 0) {
            std.debug.print("Error: sched_yield failed\n", .{});
        }
        // Other processing or wait conditions
    }
}
```

In this example, sched_yield() could be used in a wait loop, though it’s typically better to rely on blocking operations.

### Summary:
  - CFS offers a fair, dynamically adjustable scheduling model that adapts based on process load and priority, using concepts like target latency and minimum granularity.
  - sched_yield() provides a mechanism for processes to voluntarily give up the CPU, although it’s usually better to rely on the OS for efficient scheduling and event-driven programming for inter-process synchronization.

These concepts provide more efficient CPU usage and improved system responsiveness, particularly important for interactive applications

## Process Priorities

Linux uses priorities to determine the order and duration a process runs on the CPU. Priorities are managed using nice values which range from -20 to 19:
  - A low nice value (e.g., -20) gives the process higher priority and more CPU time.
  - A high nice value (e.g., 19) lowers the process priority, giving it less CPU time.

Higher-priority processes (low nice values) will run more often, while lower-priority processes (high nice values) yield to others.
Nice System Call in Zig

The nice() system call allows a process to adjust its nice value. Here’s how you might increment a process's nice value in Zig:

```zig
const std = @import("std");
const errno = @import("std").os.linux.errno;

fn setNice(inc: i32) !void {
    var ret: i32 = std.os.linux.nice(inc);
    if (ret == -1 and errno.get() != 0) {
        std.debug.print("Error: unable to change nice value\n", .{});
        return error.NiceError;
    } else {
        std.debug.print("New nice value: {}\n", .{ret});
    }
}

pub fn main() void {
    setNice(10) catch |err| std.debug.print("Failed with error: {}\n", .{err});
}
```

In this example:

  - nice(inc) increases the current process’s nice value by inc.
  - Checking errno helps detect if nice() failed, as -1 can also indicate success.

## Using getpriority() and setpriority()

The getpriority() and setpriority() calls provide finer control over process priorities, allowing adjustments for specific processes or groups:

```zig

fn getPriority() i32 {
    return std.os.linux.getpriority(std.os.linux.PRIO_PROCESS, 0);
}

fn setPriority(prio: i32) !void {
    const ret = std.os.linux.setpriority(std.os.linux.PRIO_PROCESS, 0, prio);
    if (ret == -1) {
        return error.PriorityError;
    }
}
```

In getPriority(), PRIO_PROCESS targets the current process. Similarly, setPriority() changes the priority, with 0 referring to the current process ID.

## Processor Affinity

Processor affinity in Linux refers to binding a process to a specific CPU to improve performance by reducing CPU cache invalidation. Linux distinguishes between:

  - Soft affinity: The scheduler tries to keep processes on the same CPU for efficiency but may reassign them if needed.
  - Hard affinity: The process is restricted to run only on assigned CPUs.

### sched_getaffinity() and sched_setaffinity() in Zig

These functions retrieve or set CPU affinities for a process using a cpu_set_t structure, representing the CPUs a process can run on.

Example of setting affinity in Zig:

```zig
const std = @import("std");
const sched = @import("std").os.linux.sched;

fn setCPUAffinity(cpu: u32) !void {
    var set: sched.cpu_set_t = sched.cpu_set_t.init();
    set.add(cpu);

    const ret = sched.setaffinity(0, &set); // 0 means current process
    if (ret == -1) {
        return error.AffinityError;
    }
}

pub fn main() void {
    setCPUAffinity(1) catch |err| std.debug.print("Failed with error: {}\n", .{err});
}
```

#### In this example:

  - sched.cpu_set_t.init() initializes an empty CPU set.
  - set.add(cpu) adds a specific CPU to the set.
  - sched.setaffinity(0, &set) applies the affinity for the current process.

#### Key Concepts Recap

  - Process Priorities: Managed by nice values, determining CPU time allocation.
  - Processor Affinity: Defines which CPUs a process can run on, optimizing cache usage and CPU efficiency.

Each of these concepts allows precise control over CPU resource allocation, making it possible to prioritize or bind processes for performance improvements in multi-tasking environments. Let me know if you need further elaboration on any part!

## 1. Real-Time Systems Overview

A real-time system is designed to respond to inputs or "stimuli" within defined deadlines. The system’s ability to adhere to these deadlines defines its effectiveness and purpose. A real-time system isn't inherently "fast" in the traditional sense but is instead predictable within a time constraint.

Example: An Anti-lock Braking System (ABS) in cars is real-time because it needs to react quickly to braking input by adjusting the brake pressure to prevent the wheels from locking.

## 2. Types of Real-Time Systems

  - Hard Real-Time Systems: Failing to meet deadlines constitutes a critical failure. Examples include medical devices and military systems.
  - Soft Real-Time Systems: Missing deadlines is tolerated occasionally, though it may degrade performance or user experience. Examples include multimedia applications and video games.

## 3. Latency, Jitter, and Deadlines

  - Latency: The delay from stimulus to response.
  - Jitter: Variability in the latency across responses. In hard real-time systems, jitter should be near zero to ensure consistent timing.
  - Deadlines: The maximum time allowed for a response. Hard real-time systems treat missed deadlines as failures, while soft real-time systems allow occasional deadline misses.

## 4. Real-Time Scheduling Policies in Linux

Linux provides various scheduling policies to manage process priorities:

  - FIFO (First-In, First-Out): Processes with the highest priority run uninterrupted unless blocked or a higher-priority process becomes runnable.
  - RR (Round-Robin): Similar to FIFO, but processes of the same priority take turns based on assigned timeslices.
  - SCHED_OTHER: The standard scheduling policy for non-real-time processes.
  - SCHED_BATCH: Low-priority policy, ideal for background jobs that only run when no other tasks are waiting.

### Code Example: Setting Real-Time Scheduling Policy in Zig

In Linux, we can set a process’s real-time scheduling policy using sched_setscheduler from <sched.h>. Let's implement a simple function in Zig that sets the scheduling policy for a process.

This example will:

  - Set the current process to SCHED_FIFO or SCHED_RR.
  - Specify a priority level within the real-time range (1–99).

Step-by-Step Code in Zig

```zig

const std = @import("std");

pub fn set_real_time_scheduling(policy: u32, priority: i32) !void {
    const sched = @cImport({
        @cInclude("sched.h");
        @cDefine("SCHED_FIFO", 1); // FIFO scheduling
        @cDefine("SCHED_RR", 2);   // Round-robin scheduling
    });

    var schedParam: sched.sched_param = .{ .sched_priority = priority };

    // Setting the scheduling policy
    const result = sched.sched_setscheduler(0, policy, &schedParam);
    if (result != 0) {
        std.debug.print("Error setting real-time scheduling: {}\n", .{std.os.linux.errno});
        return error.SchedulingError;
    }
    std.debug.print("Real-time scheduling set to policy: {}, with priority: {}\n", .{policy, priority});
}

pub fn main() void {
    const policy = 1; // Use 1 for SCHED_FIFO, 2 for SCHED_RR
    const priority = 10; // Set priority between 1–99

    if (set_real_time_scheduling(policy, priority)) |err| {
        std.debug.print("Failed to set scheduling: {}\n", .{err});
    }
}
```

Explanation of Code

  - C Imports: We import the necessary definitions from <sched.h> for SCHED_FIFO and SCHED_RR.
  - sched.sched_setscheduler: This system call sets the scheduling policy for a given process. Here, we set the scheduling policy of the current process by passing 0 as the pid.
  - Error Handling: If sched_setscheduler fails, it returns an error code, which we handle with Zig’s std.os.linux.errno.
  - Running and Testing: Adjust policy and priority values in main to test different scheduling configurations.

Important Notes

  - Testing as Root: Setting real-time policies often requires root privileges. Run this code with elevated permissions.
  - Choose Policies Carefully: Hard real-time policies can lead to resource contention if not managed properly, as they prioritize certain processes above all others.

## Setting Scheduling Parameters in Zig

In Linux, scheduling parameters can be set for processes to control the CPU resources they receive, which is crucial in real-time systems. Here’s how to work with parameters like priority in Zig, building on the functionality provided by POSIX. In Zig, we can interact with these parameters using the Zig libc bindings or directly through system calls.

### 1. sched_getparam() and sched_setparam()
The sched_getparam and sched_setparam functions allow us to retrieve and set the priority of a process based on a scheduling policy. The priority value is defined in struct sched_param.
Example: Retrieve and Set Process Priority in Zig

  1. Define the scheduling parameters:
```zig
    const std = @import("std");

    pub fn main() !void {
        var sp: std.os.sched_param = .{ .sched_priority = 0 };
        var ret: i32 = 0;

        // Retrieve the current priority
        ret = sched_getparam(0, &sp);
        if (ret == -1) {
            std.debug.print("Error in sched_getparam: {}\n", .{std.os.linux.getErrno()});
            return;
        }
        std.debug.print("Current priority is {}\n", .{sp.sched_priority});

        // Set a new priority
        sp.sched_priority = 1; // Replace with a valid priority value for your system
        ret = sched_setparam(0, &sp);
        if (ret == -1) {
            std.debug.print("Error in sched_setparam: {}\n", .{std.os.linux.getErrno()});
            return;
        }
        std.debug.print("Priority set to {}\n", .{sp.sched_priority});
    }
```
### Explanation:
  - sched_getparam(0, &sp) retrieves the priority of the calling process (pid = 0) and stores it in sp.sched_priority.
  - sched_setparam(0, &sp) sets the priority of the calling process to the specified value in sp.sched_priority.

### 2. sched_get_priority_min and sched_get_priority_max

To ensure portability, instead of hardcoding priorities, we retrieve the minimum and maximum valid priority values using sched_get_priority_min and sched_get_priority_max.
Example: Check Priority Range in Zig

```zig
pub fn check_priority_range(policy: i32) !void {
    const min_priority = sched_get_priority_min(policy);
    if (min_priority == -1) {
        std.debug.print("Error getting min priority: {}\n", .{std.os.linux.getErrno()});
        return;
    }

    const max_priority = sched_get_priority_max(policy);
    if (max_priority == -1) {
        std.debug.print("Error getting max priority: {}\n", .{std.os.linux.getErrno()});
        return;
    }

    std.debug.print("Priority range for policy {}: {} - {}\n", .{policy, min_priority, max_priority});
}
```

### Explanation:
  - sched_get_priority_min and sched_get_priority_max check the allowed priority range for the scheduling policy.
  - This function can be used before setting priorities to confirm that the chosen value is within the allowed range.

### 3. sched_rr_get_interval()

In SCHED_RR scheduling, processes share CPU time in a round-robin manner, where each process is allotted a timeslice. We can retrieve the timeslice duration using sched_rr_get_interval.
Example: Retrieve Timeslice Duration in Zig

```zig

pub fn get_timeslice_duration() !void {
    var tp: std.os.timespec = .{ .tv_sec = 0, .tv_nsec = 0 };
    const ret = sched_rr_get_interval(0, &tp);

    if (ret == -1) {
        std.debug.print("Error getting timeslice duration: {}\n", .{std.os.linux.getErrno()});
        return;
    }

    const timeslice_ms = (tp.tv_sec * 1000) + (tp.tv_nsec / 1000000);
    std.debug.print("Timeslice duration is {} milliseconds\n", .{timeslice_ms});
}
```

### Explanation:
  - sched_rr_get_interval(0, &tp) retrieves the timeslice duration for the calling process, which is then converted to milliseconds for easier readability.

## Error Codes and Their Handling

Each of these system calls can fail, so we handle common error codes such as:

  - EFAULT: Invalid pointer passed.
  - EINVAL: Invalid priority value or policy.
  - EPERM: Insufficient permissions to modify process priority.
  - ESRCH: Process with given PID doesn’t exist.

Using std.os.linux.getErrno(), we can retrieve and interpret these errors to provide helpful debugging information.
### Real-Time Process Precautions

Real-time processes can run indefinitely without interruption, potentially making the system unresponsive. In such scenarios, it's helpful to design real-time applications with caution to avoid system instability.

## Resource Limits
### 1. Understanding Resource Limits

In Linux, the kernel controls various resources a process can use, placing limits on things like memory, CPU time, open files, and more. These restrictions ensure that one process doesn't consume too much of a system's resources, potentially affecting others. Resource limits have two key parts:

  - Soft Limit: This is the current, flexible ceiling for resource use. The process can increase or decrease this limit, up to the hard limit.
  - Hard Limit: This is the absolute maximum a process can reach for a resource. Only a privileged user (like root) can raise the hard limit, but it can be lowered.

Example: Suppose the limit on open files (RLIMIT_NOFILE) is set. If your process tries to open more than the set number of files, it will fail, preventing overuse of the file descriptors.

### 2. Why Use getrlimit and setrlimit?

Linux provides two main functions to manage these limits:

  - getrlimit: This function lets you check the current resource limits.
  - setrlimit: This function allows you to modify the resource limits, within the constraints discussed (i.e., you can increase soft limits but only reduce hard limits unless privileged).

These are typically called with constants representing each resource (like RLIMIT_NOFILE for open files or RLIMIT_CPU for CPU time). Each limit is defined by the rlimit struct:
```c
struct rlimit {
    rlim_t rlim_cur; // soft limit
    rlim_t rlim_max; // hard limit
};
```
In Zig, we can define and manage these values similarly, by working with the kernel’s system calls and struct types.

### 3. Resource Limits in Action

Example Workflow: Let's say you want to check and set limits on core file sizes (RLIMIT_CORE). First, you'd retrieve the current limits with getrlimit, then, if needed, adjust the rlim_cur (soft limit) and rlim_max (hard limit) values before applying them with setrlimit.

I'll guide you through how to set this up in Zig, along with each step and code example.

#### Example Code: Checking a Resource Limit in Zig

We’ll write a small program to retrieve the RLIMIT_CORE limit, showing you the steps to access system calls and manage these limits in Zig.

```zig

const std = @import("std");

pub fn main() !void {
    // Define the rlimit struct with soft and hard limit fields
    const rlimit = struct {
        rlim_cur: usize,  // soft limit
        rlim_max: usize,  // hard limit
    };

    // Initialize rlimit struct with a pointer for getting limits
    var core_limit: rlimit = .{ .rlim_cur = 0, .rlim_max = 0 };

    // Retrieve current RLIMIT_CORE limits (requires a syscall in Zig)
    const RLIMIT_CORE = 4; // constant for core dump size limits
    const syscall = @import("syscall");

    // Call `getrlimit`
    const result = syscall.getrlimit(RLIMIT_CORE, &core_limit);

    if (result == -1) {
        std.debug.print("Failed to get core limits\n", .{});
        return;
    }

    // Output the soft and hard limits for RLIMIT_CORE
    std.debug.print("RLIMIT_CORE limits: soft = {}, hard = {}\n", .{ core_limit.rlim_cur, core_limit.rlim_max });
}
```

#### This program does the following:

  - Defines rlimit Struct: This matches the structure in C, with fields for the soft (rlim_cur) and hard (rlim_max) limits.
  - RLIMIT_CORE Constant: Represents the core file size limit, usually set to a unique integer.
  - Syscall for getrlimit: Calls getrlimit, retrieving the current core file size limits and populating core_limit.
  - Prints Current Limits: Shows both the soft and hard limits for core files.

### 4. Modifying Resource Limits

If you need to adjust a limit, you'd follow the same process but call setrlimit instead. Just remember:

  - Soft Limit can go up or down within the hard limit.
  - Hard Limit can only be decreased unless you have special privileges.
