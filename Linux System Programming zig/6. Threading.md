# Threading
Threading is about managing multiple "threads" or units of execution in a single program or process. Think of a thread as a mini-program within the main program, where each thread can run independently. This allows a program to do multiple things at once, like downloading a file in the background while the main program continues to interact with the user.

In Zig, managing threads is relatively low-level compared to languages with extensive multithreading libraries. Here's a quick look at the foundational concepts:

  - Binaries - Dormant programs, ready to execute but currently inactive.
  - Processes - Active instances of binaries. Each process has memory, CPU time, and other resources.
  - Threads - Smallest units of execution in a process. Threads share memory within their parent process but can run independently.

## Why Use Threads?

Threads can be beneficial in several ways:
  - Parallelism: With multiple cores, threads can run at the same time on different cores, doing more in less time.
  - Responsiveness: Long tasks can be run on background threads so the main program remains responsive.
  - Blocking I/O: Threads allow work to continue even if some threads are waiting on file reads or network calls.

However, threading comes with challenges, particularly with data races and deadlocks. This means we need to carefully manage memory and execution order to avoid bugs that are difficult to detect and fix.

## Creating Threads in Zig

In Zig, you can create threads using std.Thread.spawn. Here’s a basic example that shows two threads running different tasks:
```zig
const std = @import("std");

fn doWork(thread_id: usize) void {
    std.debug.print("Thread {} is running\n", .{thread_id});
}

pub fn main() void {
    const num_threads = 2;
    var threads: [num_threads]std.Thread = undefined;

    for (threads) |*thread, i| {
        thread.* = try std.Thread.spawn(std.heap.page_allocator, doWork, i);
    }

    // Wait for all threads to finish
    for (threads) |thread| {
        try thread.join();
    }
    std.debug.print("All threads completed\n", .{});
}
```
Explanation:

  - doWork is the function that each thread runs. We print out which thread is currently running.
  - We create num_threads threads, each running doWork.
  - join() makes sure the main program waits for all threads to complete before moving on.

This example is parallel: each thread can run independently, and they share the same memory space, so variables can be accessed by any thread (which requires careful handling).

## Key Benefits of Multithreading

Let's quickly go over why threads can be so helpful:

  - Parallelism: Running tasks truly in parallel. For example, on a machine with 4 cores, 4 threads could theoretically run at the same time, handling CPU-heavy operations faster.
  - Improved Responsiveness: Keeping the main thread available for user interaction by offloading work to other threads.
  - Blocking I/O: Threads can allow work to proceed even if certain operations, like file access or network requests, are delayed.

## Challenges with Threading: Data Races and Deadlocks

A data race happens when two or more threads try to access the same data at the same time, and at least one of the accesses is a write. This leads to unpredictable results. To prevent this, we use mutexes or atomic operations to synchronize access to shared data.
In Zig, we can use std.Thread.Mutex to control access:
```zig
const std = @import("std");

const data = struct {
    counter: usize,
    lock: std.Thread.Mutex,
};

fn increment(shared: *data) void {
    shared.lock.lock();
    defer shared.lock.unlock();
    shared.counter += 1;
    std.debug.print("Counter incremented to {}\n", .{shared.counter});
}

pub fn main() void {
    var shared = data{
        .counter = 0,
        .lock = std.Thread.Mutex{},
    };

    var t1 = try std.Thread.spawn(std.heap.page_allocator, increment, &shared);
    var t2 = try std.Thread.spawn(std.heap.page_allocator, increment, &shared);

    try t1.join();
    try t2.join();

    std.debug.print("Final counter value: {}\n", .{shared.counter});
}
```
Explanation:

  - Mutex prevents other threads from accessing counter while one thread is modifying it.
  - lock() and unlock() ensure only one thread changes counter at any given time, preventing a data race.

## Alternatives to Multithreading

If threading becomes too complex, some alternatives include:

  - Non-blocking I/O: Performing operations asynchronously without needing multiple threads.
  - Event-driven systems: Handling many tasks using a single thread by switching between tasks as they become ready (often used in GUI and network servers).

## When to Avoid Threads

Threading can be powerful but isn't always the right solution. Using threads unnecessarily can lead to harder-to-maintain code, increase the chances of bugs, and lead to performance costs in some cases.

In summary:

  - Threads are useful for parallelism, responsiveness, and handling I/O.
  - They share memory within a process, which means synchronization is essential.
  - Zig provides basic tools to handle threads and synchronization, which require caution to prevent bugs like data races and deadlocks.

## Threading Patterns: Thread-per-Connection and Event-Driven
  1) Thread-per-Connection:
      In the thread-per-connection model, each connection (or unit of work) is handled by one dedicated thread. Imagine a restaurant where each customer gets a dedicated server to take care of them from start to finish. Here, the thread (server) is assigned a connection (customer) and stays with it until everything’s complete.
      - Example: A simple web server could create a new thread for each client request and handle the client’s data processing independently.
      - Pros: Straightforward to code, especially when handling blocking I/O. If one connection is slow, it only affects its assigned thread.
      - Cons: If there are thousands of connections, there will be thousands of threads, which can eat up memory and CPU resources fast.
      In Zig, we might use std.Thread.spawn to create threads. Here’s an example:
  ```zig
      const std = @import("std");

pub fn handle_connection(id: u32) void {
    std.debug.print("Handling connection {d}\n", .{id});
    // Simulate work
    std.time.sleep(1 * std.time.ns_per_s);
}

pub fn main() void {
    var threads: [10]std.Thread = undefined;

    // Create a thread for each connection
    for (threads) |*thread, i| {
        thread.* = std.Thread.spawn(handle_connection, .{ i }) catch |err| {
            std.debug.print("Failed to create thread: {s}\n", .{err});
            continue;
        };
    }

    // Wait for all threads to finish
    for (threads) |thread| {
        thread.wait() catch |err| {
            std.debug.print("Failed to join thread: {s}\n", .{err});
        };
    }
}
```
Each thread in this code would handle a single connection, outputting its progress and then sleeping to simulate work.

2) Event-Driven Threading:

The event-driven model avoids creating many threads by relying on a single (or few) threads with asynchronous I/O. Here, the application processes work by receiving events in an event loop, similar to how waitstaff in a food court handle multiple customers as each order is ready, rather than dedicating one server per customer.

  - Example: In a high-load server, the server can use one or a few threads and handle multiple requests asynchronously. Instead of waiting for each request’s I/O to complete, the thread moves to the next request.
  - Pros: Reduces the number of threads, saving memory and resources. Great for applications handling thousands of connections.
  - Cons: More complex code, requires carefully handling asynchronous events.

In Zig, async functions and await allow event-driven models. Here’s an example:
```zig
const std = @import("std");

pub fn async_handle_connection(id: u32) !void {
    std.debug.print("Handling connection {d} asynchronously\n", .{id});
    try std.time.sleep(1 * std.time.ns_per_s); // Simulate async work
}

pub fn main() !void {
    var connections = [_]u32{0, 1, 2, 3, 4};
    for (connections) |conn| {
        async_handle_connection(conn) catch |err| {
            std.debug.print("Failed to handle connection: {s}\n", .{err});
        };
    }
}
```
This code schedules several asynchronous tasks, and each async_handle_connection can run independently without blocking others.

### Concurrency vs. Parallelism
  - Concurrency: Multiple tasks (or threads) are running during overlapping time periods. It’s like cooking several dishes at once but working on each only when you have time. It doesn’t necessarily mean they’re running at the exact same time.
  - Parallelism: This means tasks are running at exactly the same time, utilizing multiple CPU cores. Each dish would be prepared by a different cook simultaneously.

Concurrency is achievable on single-core systems, while parallelism needs multi-core processors.

### Race Conditions
Race conditions occur when multiple threads access and modify shared data at the same time, leading to unpredictable results. For example, consider an ATM withdrawing money. If two people try to withdraw from the same account at the same time, both could check the balance before one completes the transaction, allowing them to withdraw more than the account holds.

To fix race conditions, we use synchronization methods, like locks or atomic operations. Here’s an example:
```zig
const std = @import("std");

const Account = struct {
    balance: i32,
    mutex: std.Thread.Mutex,
    
    pub fn withdraw(self: *Account, amount: i32) bool {
        self.mutex.lock(); // Lock the critical region
        defer self.mutex.unlock(); // Ensure unlock after work

        if (self.balance < amount) {
            return false;
        }
        self.balance -= amount;
        return true;
    }
};

pub fn main() !void {
    var account = Account{ .balance = 1000, .mutex = std.Thread.Mutex.init() };

    var thread = try std.Thread.spawn(Account.withdraw, .{ &account, 500 });
    try account.withdraw(500);

    thread.wait() catch {};
    std.debug.print("Final balance: {d}\n", .{account.balance});
}
```
In this example, using a Mutex prevents the balance from being accessed simultaneously, ensuring that two threads won’t withdraw money at the same time.
...
