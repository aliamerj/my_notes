# General Overview of Synchronization
Synchronization ensures that shared resources (like memory, files, etc.) are accessed in a controlled manner by multiple threads or processes to prevent race conditions, deadlocks, and data inconsistency.

### Common Synchronization Issues:
  1. Race conditions: Occurs when two threads access a shared resource simultaneously, and the outcome depends on the order of access.
  2. Deadlocks: Happens when two or more threads are blocked forever, each waiting on the other.
  3. Livelocks: Similar to deadlocks, but processes keep changing their state in response to each other without making progress.
    
# Synchronization Patterns
Synchronization is essential in concurrent programming, and semaphores provide a fundamental way to coordinate the activities of threads or processes. This lecture covers several common synchronization patterns using semaphores, focusing on how to ensure that different threads can work together without encountering race conditions or deadlocks.

## Key Synchronization Patterns:
1. **Signalling**: This pattern allows one thread to signal another when an event has occurred. A semaphore is used for communication between threads. Thread A performs an action and signals Thread B to proceed.

Pseudo-steps:

    Thread A: Statement A1 → post(sem)
    Thread B: wait(sem) → Statement B2

Outcome: A1 always happens before B2 irrespective of thread scheduling.

2. Rendezvous: The rendezvous pattern extends signaling to both directions. Both threads must reach certain points before either can proceed. Two semaphores are required, one for each thread.

Pseudo-steps:

    Thread A: Statement A1 → post(aArrived) → wait(bArrived) → Statement A2
    Thread B: Statement B1 → post(bArrived) → wait(aArrived) → Statement B2

Outcome: Ensures that A1 occurs before B2, and B1 happens before A2, preventing deadlock.

3. Mutual Exclusion (Mutex): This pattern ensures that only one thread can access a critical section at a time. A mutex (binary semaphore) initialized to 1 is used.

Pseudo-steps:

    Thread A/B: wait(mutex) → critical section → post(mutex)

Outcome: Only one thread can execute the critical section, ensuring no race conditions occur.

4. Multiplex: A more generalized version of mutual exclusion. With a general semaphore initialized to n, up to n threads can access the critical section simultaneously.

Pseudo-steps:

    Thread K: wait(mutex) → critical section → post(mutex)

Outcome: Limits concurrent access, like controlling database queries to avoid overload.

5. Barrier: This pattern forces multiple threads (more than two) to wait at a synchronization point until all threads reach it before proceeding.

Pseudo-steps:

    Thread K:
        Increment shared counter in critical section
        When the nth thread arrives, unblock all threads.
        Ensure no threads are permanently blocked.

Outcome: Once the last thread arrives, all threads proceed.

6. Reusable Barrier: Similar to the barrier, but the barrier can be reset, allowing threads to synchronize again. It uses a turnstile-like approach to prevent permanent blocking of threads.

### Zig Code Example for Synchronization Patterns
Let's implement the Signalling and Rendezvous patterns in Zig.
1. Signalling Pattern in Zig
```zig
const std = @import("std");

const sem = std.Thread.Semaphore.init(0);

fn threadA() void {
    // Statement A1
    std.debug.print("Thread A: Doing A1...\n", .{});
    
    // Signal thread B
    sem.post();
}

fn threadB() void {
    // Wait for signal from thread A
    sem.wait();
    
    // Statement B2
    std.debug.print("Thread B: Doing B2...\n", .{});
}

pub fn main() void {
    var a_thread = std.Thread.spawn(.{}, threadA) catch unreachable;
    var b_thread = std.Thread.spawn(.{}, threadB) catch unreachable;

    a_thread.wait();
    b_thread.wait();
}
```
Explanation:
  1. sem.post() is used by Thread A to signal Thread B that it can proceed.
  2. sem.wait() makes Thread B wait until it receives the signal.
  3. When running, the output will always show that Thread A finishes its task before Thread B starts.
     
2. Rendezvous Pattern in Zig

```zig
const std = @import("std");

const aArrived = std.Thread.Semaphore.init(0);
const bArrived = std.Thread.Semaphore.init(0);

fn threadA() void {
    std.debug.print("Thread A: Doing A1...\n", .{});
    
    // Signal Thread B that A has arrived
    aArrived.post();
    
    // Wait for Thread B to arrive
    bArrived.wait();
    
    std.debug.print("Thread A: Doing A2...\n", .{});
}

fn threadB() void {
    std.debug.print("Thread B: Doing B1...\n", .{});
    
    // Signal Thread A that B has arrived
    bArrived.post();
    
    // Wait for Thread A to arrive
    aArrived.wait();
    
    std.debug.print("Thread B: Doing B2...\n", .{});
}

pub fn main() void {
    var a_thread = std.Thread.spawn(.{}, threadA) catch unreachable;
    var b_thread = std.Thread.spawn(.{}, threadB) catch unreachable;

    a_thread.wait();
    b_thread.wait();
}
```
Explanation:
  - Two semaphores (aArrived and bArrived) allow the threads to synchronize at their rendezvous points.
  - Each thread signals the other and then waits for the signal to continue.


## Synchronization Mechanisms in Linux
Linux offers several synchronization primitives at both the user and kernel levels, commonly used in system programming.
a. Mutexes (Mutual Exclusion Locks)
  A mutex is a lock that allows only one thread to access a shared resource at a time.
  Linux Example: pthread_mutex_t in POSIX threads.
```zig
pthread_mutex_lock(&mutex);
// Critical section (only one thread can execute)
pthread_mutex_unlock(&mutex);
```
b. Spinlocks
  A spinlock is a lock where the thread continuously checks (spins) for the lock to be available. It is efficient for short critical sections but wastes CPU cycles.
  Used primarily in kernel space or in very low-level code.
  ```zig
spin_lock(&lock);
// Critical section
spin_unlock(&lock);
```
c. Semaphores
  Semaphores can allow more than one thread/process into a critical section (counting semaphore) or just one (binary semaphore).
  Useful for limiting access to resources (like limiting the number of concurrent database connections).
  ```zig
sem_wait(&sem);
// Critical section
sem_post(&sem);
```
d. Futexes (Fast User-Space Mutexes)
  Futex stands for fast userspace mutex and is a hybrid mechanism combining user-space and kernel-space synchronization. Most of the waiting is done in user-space unless blocking is required.
  ```c
syscall(SYS_futex, &futex_var, FUTEX_WAIT, expected_val, NULL);
```

## Synchronization Patterns in Zig
Zig, being a system programming language, provides several low-level primitives for synchronization but doesn't have the same high-level abstractions that other languages like Rust or Go may have. However, you can use Zig to interface with lower-level system calls or build your own synchronization patterns.

a. Mutex in Zig
Zig doesn’t have a built-in mutex type yet, but you can implement one by interfacing with pthread or using atomic operations.
Example using Zig’s standard library:
```zig
const std = @import("std");
var mutex: std.Thread.Mutex = undefined;

mutex.lock();
defer mutex.unlock();
// Critical section
```
b. Atomic Operations

Zig supports atomic operations, which are useful for lock-free synchronization mechanisms. Atomic operations ensure that read-modify-write operations on variables are done in an indivisible manner.

Example:
```zig
const std = @import("std");
var counter: u32 = 0;

std.atomic.fetchAdd(&counter, 1, .SeqCst);
```
c. Channels in Zig

Zig provides channels for message passing between threads, which can be a useful synchronization pattern in concurrent programs.
```zig
const std = @import("std");
const Channel = std.Thread.Channel(i32);

var chan = Channel.init();
chan.send(42);  // Send data
const value = chan.recv();  // Receive data
```
d. Spinlocks in Zig

A spinlock can be implemented using atomic operations. Here's an example:
```zig
const std = @import("std");

var lock: std.Atomic.Bool = std.Atomic.Bool.init(false);

fn acquire_lock() void {
    while (!std.atomic.compareExchangeBool(&lock, false, true, .SeqCst)) {}
}

fn release_lock() void {
    lock.store(false, .SeqCst);
}
```

## Common Synchronization Patterns
Here are a few commonly used synchronization patterns in both system and application development:

a. Producer-Consumer Pattern

This pattern ensures that one or more producer threads generate data and one or more consumer threads process the data. A bounded buffer (queue) is often used to hold the produced data.

  - Synchronization: Typically uses mutexes or semaphores to ensure that the producer doesn’t overwrite the buffer and the consumer doesn’t read from an empty buffer.

b. Reader-Writer Locks

In scenarios where many threads only need read access to shared data and only a few need write access, reader-writer locks are used. Multiple readers can access data simultaneously, but writers need exclusive access.

  - Linux: pthread_rwlock_t provides this functionality.
    ```zig
    pthread_rwlock_rdlock(&rwlock);
    // Reading section
    pthread_rwlock_unlock(&rwlock);

    pthread_rwlock_wrlock(&rwlock);
    // Writing section
    pthread_rwlock_unlock(&rwlock);
    ```

c. Barrier Synchronization

A barrier is a synchronization mechanism where all threads or processes must reach a certain point before any can proceed. This is useful in parallel algorithms where certain phases of the algorithm must be completed before moving forward.
d. Spin-waiting / Busy-waiting

Threads repeatedly check a condition until it is satisfied, which is efficient for short wait times but wastes CPU cycles. This is sometimes used in spinlocks.

### Advanced Patterns
  - Lock-free Algorithms: These algorithms avoid locking mechanisms by using atomic operations and careful memory ordering, thus eliminating the risk of deadlocks but introducing complexity.
  - Thread Pools: A thread pool manages a set of pre-created threads to handle tasks. It is often used to avoid the overhead of creating and destroying threads for every new task.

### Best Practices in Synchronization
   a. Minimize the critical section: Keep the part of the code where locks are held as short as possible to reduce contention and improve performance.4
   b. Use atomic operations if possible: For simple counters or flags, atomic operations can be more efficient than locking.
   c. Avoid deadlocks: Always acquire locks in a consistent order and avoid holding multiple locks if not necessary.
   d. Use lock-free or wait-free algorithms: These algorithms, though complex, can improve performance, especially in real-time or high-concurrency environments.

### Summary

Synchronization is essential in both system programming and application development, especially in multi-threaded or multi-process environments. Depending on your application’s requirements, you can choose between simple locking mechanisms (like mutexes) or more advanced lock-free approaches (like atomics and spinlocks). In Zig, synchronization mechanisms can be implemented using standard library features or directly interfacing with OS-level system calls.
