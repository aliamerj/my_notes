#  Threads and Concurrency

## Threads:
Threads are lightweight units of execution within a process. They share the same memory space but have separate execution stacks.
Multithreading is used to improve the efficiency of programs by allowing them to perform multiple tasks at once.
Thread Safety:

When multiple threads access shared resources, it's essential to handle synchronization properly to avoid race conditions.
Mutexes and semaphores are common synchronization tools used to ensure that only one thread modifies a resource at a time.

## Thread Lifecycle:

Threads can be in different states: created, running, waiting, blocked, or terminated.
A thread starts by invoking a function and terminates when that function completes or an explicit termination call (like pthread_exit() in Linux).

## Thread Cancellation:
- Asynchronous Cancellation: Terminates a thread immediately.

- Deferred Cancellation: A thread is informed of its cancellation and checks regularly if it should terminate, giving it time to clean up resources.

- Cancellation Mechanism: pthread_cancel cancels a thread, and pthread_testcancel is used within the target thread to check if it has been canceled.

- Cleanup Handlers: If a thread is terminated, registered cleanup handlers ensure proper resource cleanup. pthread_cleanup_push() registers a cleanup function, and pthread_cleanup_pop() executes it if necessary.

### Concurrency vs. Parallelism:
- Concurrency refers to tasks making progress by being managed in overlapping periods of time. This doesn't necessarily mean tasks are running at the same time (which is parallelism).
- Parallelism occurs when tasks run simultaneously, often on multiple cores.

## Concurrency and Data Sharing:
Threads can share memory, which allows them to access and modify shared data, but improper handling can lead to data inconsistencies or "race conditions."
Using `pthread_join()` ensures that one thread waits for another to complete before accessing shared data, preventing early reads.

## Concurrency on Multi-core Processors:
Multi-core systems can execute multiple threads in parallel, but if there are more threads than cores, time-slicing allows the CPU to switch between threads, making it appear that tasks are running concurrently.

## Parallelism and Speedup:
Multi-threading may not always result in a faster completion time due to overhead and task dependencies. Tasks need to be properly parallelized for significant speed improvements.

## Example of Thread Cancellation and Cleanup in Zig
This Zig code demonstrates thread cancellation with deferred checks and resource cleanup using a simple structure allocation and deallocation mechanism.

## Example of Thread Cancellation and Cleanup in Zig
This Zig code demonstrates thread cancellation with deferred checks and resource cleanup using a simple structure allocation and deallocation mechanism.
```zig
const std = @import("std");

const Job = struct {
    // Simulating a job with allocated memory.
    data: ?[]u8 = null,
};

fn cleanup(mem: *Job) void {
    std.log.info("Cleaning up allocated memory", .{});
    if (mem.data) |d| {
        std.heap.page_allocator.free(d);
        mem.data = null;
    }
}

fn doWork(job: *Job, cancel: *bool) !void {
    // Register a cleanup handler (using defer in Zig).
    defer cleanup(job);

    // Allocate memory (representing job's work).
    job.data = try std.heap.page_allocator.alloc(u8, 1024);
    
    while (true) {
        if (cancel.*) {
            std.log.info("Cancellation requested, cleaning up", .{});
            return;
        }

        // Simulate doing some work.
        std.log.info("Working...", .{});
        std.time.sleep(1 * std.time.ns_per_sec); // Sleep to simulate work
    }
}

pub fn main() void {
    var job = Job{};
    var cancel = false;

    var th = try std.Thread.spawn(.{}, doWork, &job, &cancel);
    
    // Simulate user cancellation after some time.
    std.time.sleep(3 * std.time.ns_per_sec); 
    std.log.info("Requesting thread cancellation", .{});
    cancel = true;
    
    // Wait for thread to complete.
    th.wait() catch {};
    std.log.info("Thread work completed", .{});
}
```
## Translation of Key Features from C to Zig
- Thread Creation: In Zig, thread creation is done using std.Thread.spawn() which is similar to pthread_create(). It requires a function pointer and arguments.

- Thread Cancellation: In the C example, pthread_cancel() and pthread_testcancel() handle thread cancellation. In Zig, we mimic this by checking the cancellation flag (cancel in this case) periodically inside the thread's work loop.

- Cleanup Handlers: In C, pthread_cleanup_push() and pthread_cleanup_pop() register and execute cleanup handlers. In Zig, we use defer to register a cleanup action, ensuring that resources are properly deallocated when the thread terminates, whether by cancellation or completion.

## Threads and Concurrency in Linux:
### 1. POSIX Threads (pthreads):
  - Linux provides support for threads via the pthreads library, which allows the creation, management, and synchronization of threads.
  - Key functions include:
      - pthread_create(): Creates a new thread.
      - pthread_join(): Waits for a thread to finish execution.
      - pthread_mutex_lock() / pthread_mutex_unlock(): To lock/unlock a mutex.
      - pthread_cond_wait() / pthread_cond_signal(): Used for condition variable synchronization.

### 2. Kernel Threads:
- In Linux, threads are implemented as kernel-level threads. Each thread is treated similarly to a process, and they share resources like memory space, file descriptors, etc.
- Threads are created using the clone() system call in Linux, which allows fine-grained control over resource sharing between the parent and child thread.
  
### 3. Thread Scheduling:
- Linux uses a completely fair scheduler (CFS) to schedule threads and processes, aiming for fairness in CPU time allocation.
- Threads can have different scheduling policies: real-time or normal scheduling. Real-time threads have higher priority and get scheduled first.

## Threads and Concurrency in Zig:
###  Zigâ€™s Concurrency Model:
- Zig has a minimalistic concurrency model that supports threads and cooperative multitasking using async and await.
- Zig provides a basic std.Thread module to manage threads, allowing the creation and synchronization of threads.

### Zig `std.Thread` Module:
- Creating Threads:
std.Thread.spawn is used to create a thread in Zig. It spawns a new thread that runs a given function.
Example:
```zig
const std = @import("std");

fn threadFunc(arg: usize) void {
    std.debug.print("Thread running with arg: {}\n", .{arg});
}

pub fn main() void {
    var t = try std.Thread.spawn(threadFunc, 42);
    t.wait(); // Wait for the thread to finish
}
```
### Synchronization in Zig:
Zig uses mutexes and condition variables to synchronize threads. These are provided by `std.Thread.Mutex` and `std.Thread.Cond`.
Mutex Example:
```zig
const std = @import("std");

var mutex = std.Thread.Mutex.init();

fn protectedFunc() void {
    mutex.lock();
    defer mutex.unlock();
    // Critical section
}

pub fn main() void {
    var t1 = try std.Thread.spawn(protectedFunc);
    var t2 = try std.Thread.spawn(protectedFunc);

    t1.wait();
    t2.wait();
}
```

### Cooperative Multitasking in Zig:

Zig supports an async model for cooperative multitasking, which allows multiple tasks to be interleaved on a single thread using async and await.
Concurrency in this model is cooperative, where tasks must manually yield control, unlike thread-based concurrency which relies on the OS for scheduling.

### Thread-Local Storage (TLS):

Thread-local storage allows each thread to have its own separate instance of a variable.
In Zig, @threadLocal can be used to mark a variable as thread-local.
```zig
var tlsVar: i32 = 0;
const threadLocal = @threadLocal;

fn threadFunc() void {
    tlsVar = 42; // Each thread will have its own tlsVar instance
}
```
### Key Challenges in Concurrency:
#### 1.Deadlocks:
A deadlock occurs when two or more threads are blocked forever, each waiting for a resource the other holds.
Avoiding deadlocks requires careful management of resource acquisition orders or using techniques like try-locking.

#### 2.Race Conditions:
Race conditions happen when the outcome of a program depends on the sequence or timing of uncontrollable events like thread scheduling.
Proper synchronization (e.g., using mutexes or atomic operations) is necessary to avoid race conditions.

#### 3.Starvation:
This occurs when a thread never gets scheduled or executed because other threads are constantly prioritized over it.

#### 4.Load Balancing in Multithreaded Applications:
Efficient thread load balancing across CPUs or cores is essential to avoid bottlenecks and ensure optimal performance.
Thread pools and work-stealing algorithms are common methods to manage concurrency and balance workloads.

## Key Concepts:
- Deferred Cancellation in Zig: This is done by checking a flag (cancel in this case) inside the thread function to determine if cancellation was requested.
- Cleanup with defer: Zig uses defer to ensure that resources (like memory in the example) are cleaned up regardless of how the thread exits.
  
